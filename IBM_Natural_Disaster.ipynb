{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the training and testing set for the ImageDataGenerator \n",
    "gen_train = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "gen_test=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 742 images belonging to 4 classes.\n",
      "Found 198 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Load the training and testing data\n",
    "x_train = gen_train.flow_from_directory(r'C:\\Users\\hp\\Desktop\\IBM\\dataset\\train_set',target_size=(64, 64),batch_size=5,\n",
    "                                            color_mode='rgb',class_mode='categorical')\n",
    "x_test = gen_test.flow_from_directory(r'C:\\Users\\hp\\Desktop\\IBM\\dataset\\test_set',target_size=(64, 64),batch_size=5,\n",
    "                                            color_mode='rgb',class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}\n"
     ]
    }
   ],
   "source": [
    "#Print the labels of training set\n",
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}\n"
     ]
    }
   ],
   "source": [
    "#Print the labels of testing set\n",
    "print(x_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 220, 1: 156, 2: 198, 3: 168})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the number of images under each label\n",
    "from collections import Counter as c\n",
    "c(x_train .labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Convolutional 2D model\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 27, 27, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3872)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               495744    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 524,900\n",
      "Trainable params: 524,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "149/149 [==============================] - 43s 292ms/step - loss: 1.0593 - accuracy: 0.5094 - val_loss: 1.1511 - val_accuracy: 0.5253\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 43s 290ms/step - loss: 0.9524 - accuracy: 0.6092 - val_loss: 1.3233 - val_accuracy: 0.4596\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 44s 293ms/step - loss: 0.8538 - accuracy: 0.6092 - val_loss: 0.9303 - val_accuracy: 0.5909\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 43s 284ms/step - loss: 0.8011 - accuracy: 0.6469 - val_loss: 0.8818 - val_accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 43s 286ms/step - loss: 0.7364 - accuracy: 0.6819 - val_loss: 0.9443 - val_accuracy: 0.5657\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 44s 296ms/step - loss: 0.6977 - accuracy: 0.7170 - val_loss: 1.0209 - val_accuracy: 0.5606\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 44s 297ms/step - loss: 0.6428 - accuracy: 0.7345 - val_loss: 0.9682 - val_accuracy: 0.6313\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 42s 284ms/step - loss: 0.6534 - accuracy: 0.7439 - val_loss: 0.9451 - val_accuracy: 0.6364\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 45s 306ms/step - loss: 0.5492 - accuracy: 0.7938 - val_loss: 0.8863 - val_accuracy: 0.6869\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 45s 303ms/step - loss: 0.5115 - accuracy: 0.8019 - val_loss: 1.0207 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c83d025f8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=10, validation_data=x_test,validation_steps = len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('disaster.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = classifier.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
